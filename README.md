# The StudentEval Dataset

1. The dataset is available via the Open Science Framework: https://doi.org/10.17605/OSF.IO/WDPSX

2. `dataset.ipynb` has the basic analysis that we perform in this section.

3. figures are generated by `plots.Rmd`

# Results

## How Do Models Perform on StudentEval?

There are three steps to reproduce the results of this section:

1. Generate completions for each model, which creates the files
   `../computed_data/completions_*.jsonl`
2. Execute the generated completions, which creates the files
   `../computed_data/executions_*.csv`
3. Analyze the results with `compute_pass1.ipynb`

### Generating Completions

Use the following command to generate GPT-3.5 Turbo completions:

```
python3 completions.py \
    --model-type openai \
    --completions ../computed_data/completions_gpt35turbo-0301.jsonl \
    --engine gpt-35-turbo-0301 \
    --api-base <API_BASE> \
    --api-version 2022-12-01
```

You will need to set `<API_BASE>` to a gpt-35-turbo-0301 API endpoint, and
the `OPENAI_API_KEY` environment variable.

Use the following command to generate StarChat-Alpha completions:

```
python3 completions.py \
    --model-type automodel \
    --completions ../computed_data/completions_starchat-alpha.jsonl \
    --max-workers=150 \
    --model-path HuggingFaceH4/starchat-alpha
```

Use the following command to generate SantaCoder completions:

```
python3 completions.py \
    --model-type automodel \
    --completions ../computed_data/completions_santacoder.jsonl \
    --max-workers=1000 \
    --model-path bigcode/gpt_bigcode-santacoder
```

Use the following command to generate StarCoderBase completions:

```
python3 completions.py \
    --model-type automodel \
    --completions ../computed_data/completions_starcoderbase.jsonl \
    --max-workers=100  \
    --model-path bigcode/starcoderbase
```

Use the following command to generate Replit-Code-v1 completions:

```
python3 completions.py \
    --model-type automodel \
    --completions ../computed_data/completions_replitcode1.jsonl \
    --max-workers=200 \
    --model-path replit/replit-code-v1-3b
```

Notes:

1. In the commands above, the `--max-workers` argument is the batch size and
   we have chosen values that are suitable for an 80GB GPU. Revise them down
   if needed.
2. You must be logged into the Hugging Face Hub and accept the StarCoder model
   license to download the model.
3. Replit-Code-v1 has non-standard dependencies.


### Executing Generated Completions

Use the following commands:

```
python3 executions.py \
    --completions ../computed_data/completions_gpt35turbo-0301.jsonl \
    --executions ../computed_data/executions_gpt35turbo-0301.csv

python3 executions.py \
    --completions ../computed_data/completions_starchat-alpha.jsonl \
    --executions ../computed_data/executions_starchat-alpha.csv

python3 executions.py \
    --completions ../computed_data/completions_santacoder.jsonl \
    --executions ../computed_data/executions_santacoder.csv

python3 executions.py \
    --completions ../computed_data/completions_starcoderbase.jsonl \
    --executions ../computed_data/executions_starcoderbase.csv

python3 executions.py \
    --completions ../computed_data/completions_replitcode1.jsonl \
    --executions ../computed_data/executions_replitcode1.csv
```
### Variation in Pass@1

This is generated by `plots.Rmd`.

### Participant Success Rates

This is generated by `plots.Rmd`.

## What Makes a Successful Prompt?

The results of this section are computed in several R and Jupyter notebooks
that rely on the CSV files generated in the previous section.

1. *Trends in Student Word Choice*: `tfidf_tokenization.ipynb`

2. *Statistical Significance of Prompt Wording Choices*: `regression.Rmd`

3. *Inspecting Visual Representations*: `retrieve_embeddings.ipynb`

4. *Ambiguity in Prompts*: `prompt_ambiguity.ipynb`
