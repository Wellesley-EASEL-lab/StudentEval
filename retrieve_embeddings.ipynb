{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e131db6-0233-4ded-bde6-00721e6d4eb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb53953-26aa-4826-ac30-d5143bfc1b46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import csv\n",
    "import os\n",
    "import datasets\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0518acd5-7e77-482c-85e0-900dbfb677d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = AutoModelForCausalLM.from_pretrained(\"/data/bigcode-starcoder\",output_hidden_states=True).half().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35be85f3-be3b-4983-be42-d7b615681282",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(\"/data/bigcode-starcoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c708a263-240c-479a-a0f0-df847791ca90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def retrieve_embedding(prompt):\n",
    "    inputs = tokenizer(prompt,return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = model(**inputs)\n",
    "    last_hidden = outputs['hidden_states'][-1]\n",
    "    avg = torch.mean(last_hidden,dim=1)\n",
    "    return avg.cpu().detach().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa41ea53-09d0-4a2d-83e9-f7aa7122585f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pickle_embedding(embedding,prompt,filename):\n",
    "    data = {\"input\": prompt, \"embedding\": embedding, \"model\": \"BigCode\"}\n",
    "    with open(filename, \"ab\") as f:\n",
    "        pickle.dump(data, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78e6599-a11a-4464-834b-f124cfe5196e",
   "metadata": {},
   "source": [
    "Notice how I'm loading the data below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2178e879-2cc5-4d4f-b2b8-7b00c9758420",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "interactions_csv = pd.read_csv(\"./raw_data/interactions.csv\", index_col=0)\n",
    "print(\"Not all rows displayed below.\")\n",
    "interactions_csv.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74707652-9511-498f-95c0-69fc1959cc31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "interaction_dataset_by_id = {int(interaction[\"id\"]): interaction for index, interaction in interactions_csv.iterrows()}\n",
    "interaction_dataset_by_id[4908][\"prompt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e40db54-8d6d-4a6b-ae4d-4f8002ef8fa9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for id, interaction in interaction_dataset_by_id.items():\n",
    "    filename = f\"embeddings/embedding_{id}_bigcode.pkl\"\n",
    "    if not os.path.exists(filename):\n",
    "        prompt = interaction['prompt']\n",
    "        if prompt is not None:\n",
    "            embedding = retrieve_embedding(prompt)\n",
    "            pickle_embedding(embedding,prompt,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e04614c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"raw_data/problems.yaml\") as f:\n",
    "    problems_file = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "golden_embeddings_dir = Path(\"embeddings/golden_embeddings\")\n",
    "golden_embeddings_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "golden_prompts = {}\n",
    "for problem in problems_file:\n",
    "    golden_embedding_filename = golden_embeddings_dir / f\"{problem}_bigcode.pkl\"\n",
    "    signature = problems_file[problem][\"signature\"]\n",
    "    description = problems_file[problem][\"working_description\"]\n",
    "    prompt = f'{signature}    \"\"\"\\n    {description}    \"\"\"\\n    '\n",
    "    golden_prompts[problem] = prompt\n",
    "    if not golden_embedding_filename.exists():\n",
    "        embedding = retrieve_embedding(prompt)\n",
    "        pickle_embedding(embedding,prompt,golden_embedding_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f326f882-13ee-41cd-bc86-5a7201919a6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_past_embeddings(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        embedding = pickle.load(f)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e28d99b-2d36-4360-87fb-a1ee973f564c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "load_past_embeddings(\"embeddings/golden_embeddings/exp_bigcode.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9c4d2f-c91e-462b-a1d1-d6dbaa72d323",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_all_past_embeddings(path):\n",
    "    import re\n",
    "    retval=[]\n",
    "    for f in path.glob(\"embedding_*_bigcode.pkl\"):\n",
    "        info = re.compile(r'embedding_(?P<id>\\d+)_(?P<model>.+).pkl').search(f.name)\n",
    "        info = info.groupdict()\n",
    "        emb = load_past_embeddings(f)\n",
    "        if interaction_dataset_by_id.get(int(info[\"id\"])) is not None:\n",
    "            emb[\"interaction\"] = interaction_dataset_by_id[int(info[\"id\"])]\n",
    "            retval.append(emb)\n",
    "    return retval\n",
    "\n",
    "def load_all_golden_embeddings(path):\n",
    "    import re\n",
    "    retval = []\n",
    "    for f in path.glob(\"*_bigcode.pkl\"):\n",
    "        emb = load_past_embeddings(f)\n",
    "        emb[\"name\"] = f.name[:f.name.rfind(\"_\")]\n",
    "        retval.append(emb)\n",
    "    return retval\n",
    "\n",
    "all_embs = load_all_past_embeddings(Path(\"./embeddings\"))\n",
    "gold_embs = load_all_golden_embeddings(Path(\"./embeddings/golden_embeddings\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fde117d-96e5-42e6-8ed7-937d134d55a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "\n",
    "embs_arr = [e[\"embedding\"] for e in all_embs]\n",
    "gold_embs_index = len(embs_arr)\n",
    "gold_embs_idx_by_name = {}\n",
    "gold_embs_by_name = {}\n",
    "for gold in gold_embs:\n",
    "    gold_embs_idx_by_name[gold[\"name\"]] = gold_embs_index\n",
    "    gold_embs_by_name[gold[\"name\"]] = gold[\"embedding\"]\n",
    "    embs_arr.append(gold[\"embedding\"])\n",
    "    gold_embs_index += 1\n",
    "\n",
    "\n",
    "print(gold_embs_idx_by_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4936cc-9b35-474c-b769-a745bda3737c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embs = np.array(embs_arr)\n",
    "\n",
    "perplexity = 20\n",
    "\n",
    "embs_proj = TSNE(n_components=2, perplexity=perplexity).fit_transform(embs)\n",
    "\n",
    "passed_indices_all, failed_indices_all = [], []\n",
    "\n",
    "def is_emb_passed(emb):\n",
    "    return emb[\"interaction\"][\"tests_passed\"] == emb[\"interaction\"][\"total_tests\"]\n",
    "\n",
    "for i, emb in enumerate(all_embs):\n",
    "    if is_emb_passed(emb):\n",
    "        passed_indices_all.append(i)\n",
    "    else:\n",
    "        failed_indices_all.append(i)\n",
    "\n",
    "all_embs_idx_by_id = {emb[\"interaction\"][\"id\"]: i for i, emb in enumerate(all_embs)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300308a0-8686-46f5-b90e-dc52da0bfb4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "ax.set(xlim=(-80,80), ylim=(-80,80))\n",
    "colors = {\"pass\":\"#118AB2\", \"fail\":\"#EF476F\", \"gold\":\"#fb8500\"}\n",
    "\n",
    "ax.scatter(embs_proj[passed_indices_all, 0], embs_proj[passed_indices_all, 1], alpha=0.5, c=colors[\"pass\"], label=\"pass\")\n",
    "ax.scatter(embs_proj[failed_indices_all, 0], embs_proj[failed_indices_all, 1], alpha=0.5, c=colors[\"fail\"], label=\"fail\")\n",
    "\n",
    "ax.legend(fontsize='large', markerscale=2)\n",
    "plt.title(f\"t-SNE Projection of Last Layer Embeddings, Perplexity={perplexity}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade7265e-5364-4eac-aede-4663cd364176",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "passing_per_problem, failing_per_problem = {}, {}\n",
    "\n",
    "per_problem_idx = {}\n",
    "\n",
    "for i in range(len(all_embs)):\n",
    "    problem = all_embs[i][\"interaction\"][\"problem\"]\n",
    "    per_problem_idx[problem] = per_problem_idx.get(problem, []) + [i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf491691",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"colors.txt\") as f:\n",
    "    colors_f = f.read().splitlines()\n",
    "    colors_dict = dict(zip(colors_f[::2], colors_f[1::2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cb836d-1c12-484f-b9f3-239a0b26c58d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,10))\n",
    "color_vals = iter(colors_dict.values())\n",
    "\n",
    "for problem_i, problem in enumerate(sorted(per_problem_idx)):\n",
    "    passed_indices = [i for i in per_problem_idx[problem] if is_emb_passed(all_embs[i])]\n",
    "    failed_indices = [i for i in per_problem_idx[problem]  if is_emb_passed(all_embs[i]) == False]\n",
    "    color = next(color_vals)\n",
    "    ax.scatter(embs_proj[passed_indices, 0], embs_proj[passed_indices, 1], alpha=0.5, color=color, label=f\"{problem}:pass\")\n",
    "    ax.scatter(embs_proj[failed_indices, 0], embs_proj[failed_indices, 1], alpha=0.5, label=f\"{problem}:fail\", facecolors=\"none\", edgecolors=color)\n",
    "\n",
    "ax.legend(fontsize='small', markerscale=2, bbox_to_anchor=(1.1, 1.05), ncol=3)\n",
    "plt.title(f\"t-SNE Projection of Last Layer Embeddings, Perplexity={perplexity}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08bee96",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlim = (30, 40)\n",
    "ylim = (5, 25)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4,4))\n",
    "color_vals = iter(colors_dict.values())\n",
    "poi_ids = [4433, 4368]\n",
    "poi_label = 1\n",
    "\n",
    "for problem_i, problem in enumerate(sorted(per_problem_idx)):\n",
    "    passed_indices = [i for i in per_problem_idx[problem] if is_emb_passed(all_embs[i]) and xlim[0] <= embs_proj[i, 0] <= xlim[1] and ylim[0] <= embs_proj[i, 1] <= ylim[1]]\n",
    "    failed_indices = [i for i in per_problem_idx[problem]  if is_emb_passed(all_embs[i]) == False and xlim[0] <= embs_proj[i, 0] <= xlim[1] and ylim[0] <= embs_proj[i, 1] <= ylim[1]]\n",
    "    color = next(color_vals)\n",
    "    if len(passed_indices) > 0:\n",
    "        ax.scatter(embs_proj[passed_indices, 0], embs_proj[passed_indices, 1], alpha=0.5, color=color, label=f\"{problem}:pass\")\n",
    "    if len(failed_indices) > 0:\n",
    "        ax.scatter(embs_proj[failed_indices, 0], embs_proj[failed_indices, 1], alpha=0.5, label=f\"{problem}:fail\", facecolors=\"none\", edgecolors=color)\n",
    "    if poi_ids is not None:\n",
    "        for poi_id in poi_ids:\n",
    "            i = all_embs_idx_by_id[poi_id]\n",
    "            if i not in passed_indices and i not in failed_indices:\n",
    "                continue\n",
    "            ax.annotate(poi_label, (embs_proj[i, 0]-0.25, embs_proj[i, 1]-0.25))\n",
    "            poi_label += 1\n",
    "\n",
    "ax.legend(fontsize='small', markerscale=2)\n",
    "plt.show()\n",
    "fig.savefig(\"embeddings-testcases.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "armed-cheese",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlim = (-20, 20)\n",
    "ylim = (-60,-40)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "color_vals = iter(colors_dict.values())\n",
    "#poi_ids = [4433, 7662]\n",
    "#poi_label = 1\n",
    "\n",
    "for problem_i, problem in enumerate(sorted(per_problem_idx)):\n",
    "    passed_indices = [i for i in per_problem_idx[problem] if is_emb_passed(all_embs[i]) and xlim[0] <= embs_proj[i, 0] <= xlim[1] and ylim[0] <= embs_proj[i, 1] <= ylim[1]]\n",
    "    failed_indices = [i for i in per_problem_idx[problem]  if is_emb_passed(all_embs[i]) == False and xlim[0] <= embs_proj[i, 0] <= xlim[1] and ylim[0] <= embs_proj[i, 1] <= ylim[1]]\n",
    "    color = next(color_vals)\n",
    "    if len(passed_indices) > 0:\n",
    "        ax.scatter(embs_proj[passed_indices, 0], embs_proj[passed_indices, 1], alpha=0.5, color=color, label=f\"{problem}:pass\")\n",
    "    if len(failed_indices) > 0:\n",
    "        ax.scatter(embs_proj[failed_indices, 0], embs_proj[failed_indices, 1], alpha=0.5, label=f\"{problem}:fail\", facecolors=\"none\", edgecolors=color)\n",
    "    \"\"\"\n",
    "    if poi_ids is not None:\n",
    "        for poi_id in poi_ids:\n",
    "            i = all_embs_idx_by_id[poi_id]\n",
    "            if i not in passed_indices and i not in failed_indices:\n",
    "                continue\n",
    "            ax.annotate(poi_label, (embs_proj[i, 0]-0.25, embs_proj[i, 1]-0.25))\n",
    "            poi_label += 1\n",
    "    \"\"\"\n",
    "\n",
    "ax.legend(markerscale=2,prop={'family': 'Arial','size':14})\n",
    "plt.show()\n",
    "fig.savefig(\"embeddings-testcases.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956b5ea9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# An interactive plot of above\n",
    "\n",
    "# The following two lines are needed for the plot to show up in JupyterLab\n",
    "# import plotly.io as pio\n",
    "# pio.renderers.default=\"iframe\"\n",
    "\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import textwrap\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "color_vals = iter(colors_dict.values())\n",
    "WRAP_WIDTH = 30\n",
    "\n",
    "for problem_i, problem in enumerate(sorted(per_problem_idx)):\n",
    "    passed_indices = [i for i in per_problem_idx[problem] if is_emb_passed(all_embs[i])]\n",
    "    failed_indices = [i for i in per_problem_idx[problem]  if is_emb_passed(all_embs[i]) == False]\n",
    "    passed_hover_text = [\"PASS\"+\"<br>\".join([str(all_embs[i][\"interaction\"][\"id\"])] + textwrap.wrap(all_embs[i][\"interaction\"][\"prompt\"], width=WRAP_WIDTH)) for i in passed_indices]\n",
    "    failed_hover_text = [\"FAIL\"+\"<br>\".join([str(all_embs[i][\"interaction\"][\"id\"])] + textwrap.wrap(all_embs[i][\"interaction\"][\"prompt\"], width=WRAP_WIDTH)) for i in failed_indices]\n",
    "    golden_hover_text = \"GOLD\"+\"<br>\".join(textwrap.wrap(golden_prompts[problem], width=WRAP_WIDTH))\n",
    "    color = next(color_vals)\n",
    "    fig.add_trace(go.Scatter(x=embs_proj[passed_indices, 0], y=embs_proj[passed_indices, 1], \n",
    "                             mode='markers', marker=dict(color=color, line=dict(color=color, width=2)), name=f\"{problem}:pass\", hovertext=passed_hover_text))\n",
    "    fig.add_trace(go.Scatter(x=embs_proj[failed_indices, 0], y=embs_proj[failed_indices, 1], \n",
    "                             mode='markers', marker=dict(color=\"rgba(0,0,0,0)\",line=dict(color=color, width=2)), name=f\"{problem}:fail\", hovertext=failed_hover_text))\n",
    "    fig.add_trace(go.Scatter(x=[embs_proj[gold_embs_idx_by_name[problem], 0]], y=[embs_proj[gold_embs_idx_by_name[problem], 1]],\n",
    "                             mode='markers', marker=dict(color=color, size=10), marker_symbol=\"star\", name=f\"{problem}:canon\", hovertext=golden_hover_text))\n",
    "\n",
    "fig.update_layout(title=f\"t-SNE Projection of Last Layer Embeddings, Perplexity={perplexity}<br><sup>(Double click on the labels to select all or none)</sup>\", xaxis_title=\"x\", yaxis_title=\"y\", legend_title=\"Problem\", width=1800, height=1200)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a64d401",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(interaction_dataset_by_id[4714][\"prompt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bbebcd",
   "metadata": {},
   "source": [
    "#### Interesting observations in embeddings\n",
    "\n",
    "- `andCount`: Clearly the ones closer to the canonical prompt mentions number of '&' character while the ones further apart did not.\n",
    "\n",
    "\n",
    "- `combine`: Two set of solutions exist: left upper corner embeddings are more detailed in description (e.g. \"Takes an input of two lists, l1 and l2, each of which also contains lists. It combines the first list in l1 with the first one in l2, then continues for all items in l1 and l2. It outputs this final list which is a combination of l1 and l2.\"), and right bottom corner embeddings (including the canonical prompt) contain a much shorter description (e.g. \"combine the first half of the lists with the second half of the lists\")\n",
    "\n",
    "- `fib`: Upper left embeddings mentions the word \"Fibonacci\" while the bottom right embeddings used test-case based description (e.g. \"a function check if n==1 or n==13 or n==21\")\n",
    "\n",
    "- `sortedBooks`: A few failing prompts closer to the canonical are failing since sorting by year value is not mentioned.\n",
    "\n",
    "- `increaseScore`: Most prompts are in one cluster except for one:\n",
    "\n",
    "```\n",
    "def increaseScore(score): takes input '-10' and outputs its positive integer\n",
    "def increaseScore(score): inputs '1' and adds 9\n",
    "def increaseScore(score): adds 1 to each input '10', '15', '20'\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3bc972-93f0-427e-8e4a-556d92290ba7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Produce a 11 row 5 col combined indivisual plots\n",
    "cmap = matplotlib.colormaps[\"tab20b\"]\n",
    "norm = matplotlib.colors.Normalize(vmin=0.0, vmax=float(len(per_problem_idx)))\n",
    "figs, axs = plt.subplots(11,5,figsize=(20,44))\n",
    "\n",
    "for problem_i, problem in enumerate(sorted(per_problem_idx)):\n",
    "    ax = axs[problem_i // 5,problem_i % 5] \n",
    "    # ax.set(xlim=(-80,80), ylim=(-80,80))\n",
    "    passed_indices = [i for i in per_problem_idx[problem] if is_emb_passed(all_embs[i])]\n",
    "    failed_indices = [i for i in per_problem_idx[problem]  if is_emb_passed(all_embs[i]) == False]\n",
    "    ax.scatter(embs_proj[passed_indices, 0], embs_proj[passed_indices, 1], alpha=0.5, c=colors[\"pass\"], label=f\"{problem}:pass\")\n",
    "    ax.scatter(embs_proj[failed_indices, 0], embs_proj[failed_indices, 1], alpha=0.5, label=f\"{problem}:fail\", facecolors=\"none\", edgecolors=colors[\"fail\"])\n",
    "    ax.scatter(embs_proj[gold_embs_idx_by_name[problem], 0], embs_proj[gold_embs_idx_by_name[problem], 1], alpha=0.5, label=f\"{problem}:canonical\", marker=\"*\", color=colors[\"gold\"])\n",
    "    ax.legend(fontsize='small', markerscale=2)\n",
    "    ax.set_title(f\"t-SNE Projection of \\n Last Layer Embeddings\\nPerplexity={perplexity}, problem={problem}\", fontsize=\"small\")\n",
    "    \n",
    "\n",
    "print(\"I stopped pegging the embedding plot from (-80, -80) to (80, 80) since almost everything is clustered together\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75a991c-f853-43ab-8747-52ef4d2e85cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Produce individual plots\n",
    "def make_plots(per_problem, problems, filename_prefix=\"\", poi_ids = None, poi_label_start=0,scale=4):\n",
    "    poi_label = poi_label_start\n",
    "    for problem_i, problem in enumerate(problems):\n",
    "        fig, ax = plt.subplots(figsize=(scale,scale))\n",
    "        passed_indices = [i for i in per_problem[problem] if is_emb_passed(all_embs[i])] \n",
    "        failed_indices = [i for i in per_problem[problem]  if is_emb_passed(all_embs[i]) == False]\n",
    "        ax.scatter(embs_proj[passed_indices, 0], embs_proj[passed_indices, 1], alpha=0.5, c=colors[\"pass\"], label=f\"pass\")\n",
    "        ax.scatter(embs_proj[failed_indices, 0], embs_proj[failed_indices, 1], alpha=0.5, label=f\"fail\", facecolors=\"none\", edgecolors=colors[\"fail\"])\n",
    "        ax.scatter(embs_proj[gold_embs_idx_by_name[problem], 0], embs_proj[gold_embs_idx_by_name[problem], 1], alpha=0.5, label=f\"canonical\", marker=\"*\", color=colors[\"gold\"])\n",
    "        ax.legend(markerscale=2,prop={'family': 'Arial','size':14})\n",
    "\n",
    "        # label the points of interest\n",
    "        if poi_ids is not None:\n",
    "            cur_poi_ids = poi_ids[problem_i]\n",
    "            for label, poi_id in enumerate(cur_poi_ids):\n",
    "                i = all_embs_idx_by_id[poi_id]\n",
    "                ax.annotate(poi_label, (embs_proj[i, 0]-0.25, embs_proj[i, 1]-0.25))\n",
    "                poi_label += 1\n",
    "        \n",
    "        plt.show()\n",
    "        fig.savefig(f\"{filename_prefix}{problem}.pdf\", bbox_inches='tight')\n",
    "\n",
    "# Produce All plots:\n",
    "# make_plots(per_problem,per_problem.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3407229e-911a-4067-aadb-c8302b2bd9dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "make_plots(per_problem_idx, [\"increaseScore\", \"combine\"], \"\", [[6138, 7649], [3967, 5374]], poi_label_start=poi_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "married-sleep",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plots(per_problem_idx, [\"increaseScore\", \"combine\"], \"\", poi_label_start=poi_label,scale=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arctic-radical",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plots(per_problem_idx, [\"check_for_aspen\"],scale=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3071840d",
   "metadata": {},
   "source": [
    "## Cosine Similarities between embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5e0cfb-b556-440b-9b1a-1fbe3fd41cf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_cos_sim(emb1, emb2, prompt=\"unknown\"):\n",
    "    retval = np.dot(emb1, emb2) / (np.linalg.norm(emb1) * np.linalg.norm(emb2))\n",
    "    return retval\n",
    "\n",
    "from tqdm import tqdm\n",
    "cos_similarities = {}\n",
    "\n",
    "cos_sim_file = Path(\"computed_data/embeddings_cos_sim.csv\")\n",
    "if cos_sim_file.exists():\n",
    "    import csv\n",
    "    with open(cos_sim_file) as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for row in reader:\n",
    "            id1 = int(row[0])\n",
    "            id2 = int(row[1])\n",
    "            similarity = float(row[2])\n",
    "            cos_similarities[id1] = cos_similarities.get(id1, {})\n",
    "            cos_similarities[id1][id2] = similarity\n",
    "else:\n",
    "    for e1 in tqdm(all_embs):\n",
    "        cos_similarities[e1[\"interaction\"][\"id\"]] = cos_similarities.get(e1[\"interaction\"][\"id\"], {})\n",
    "        for e2 in all_embs:\n",
    "            if e2[\"interaction\"][\"id\"] < e1[\"interaction\"][\"id\"] and \\\n",
    "                e2[\"interaction\"][\"id\"] not in cos_similarities[e1[\"interaction\"][\"id\"]]:\n",
    "                cos_similarities[e1[\"interaction\"][\"id\"]][e2[\"interaction\"][\"id\"]] = calculate_cos_sim(e1[\"embedding\"], e2[\"embedding\"])\n",
    "    with open(cos_sim_file, \"w\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        for id1 in cos_similarities:\n",
    "            for id2 in cos_similarities[id1]:\n",
    "                writer.writerow([id1, id2, cos_similarities[id1][id2]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00084058-3504-42e6-9844-44601a025696",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import textwrap\n",
    "# Plot cosine similarity for all embeddings for some problems on one plot\n",
    "def plot_cos_similarities_vs_canon(problems):\n",
    "    fig, ax = plt.subplots(figsize=(20,10))\n",
    "    cos_sims = {}\n",
    "    for problem_i, problem in enumerate(problems):\n",
    "        gold_emb = gold_embs_by_name[problem]\n",
    "        user_embs = [all_embs[i][\"embedding\"] for i in per_problem_idx[problem]]\n",
    "        cos_sims[problem] = [calculate_cos_sim(gold_emb, user_emb) for user_emb in user_embs]\n",
    "\n",
    "    ax.boxplot(cos_sims.values(), labels=cos_sims.keys())\n",
    "    # Put labels at top\n",
    "    ax.xaxis.set_ticks_position('top')\n",
    "    ax.set_xticklabels(cos_sims.keys(), rotation=40, ha=\"left\")\n",
    "    \n",
    "    # Cut the bars to be between 0.90 and 1\n",
    "    ax.set_ylim(0.6, 1.005)\n",
    "\n",
    "    if problems == sorted(per_problem_idx.keys()):\n",
    "        title_problems = \"all\"\n",
    "    else:\n",
    "        title_problems = \"\\n\".join(textwrap.wrap(str(problems), 50))\n",
    "    plt.title(f\"Cosine Similarity of User Embeddings to Canonical Embedding\\nproblems={title_problems}\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_cos_similarities_vs_canon(sorted(per_problem_idx.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48183988-3d21-401a-a10c-69ba365ebc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot avg cosine similarity for all user embeddings for some problems on one plot\n",
    "import itertools\n",
    "def plot_cos_similarities_vs_all(problems):\n",
    "    fig, ax = plt.subplots(figsize=(20,10))\n",
    "    cos_sims = {}\n",
    "    for problem_i, problem in enumerate(problems):\n",
    "        gold_emb = gold_embs_by_name[problem]\n",
    "        user_embs = [all_embs[i][\"embedding\"] for i in per_problem_idx[problem]]\n",
    "        cos_sims[problem] = [calculate_cos_sim(user_emb1, user_emb2) for user_emb1, user_emb2 in itertools.combinations(user_embs, 2)]\n",
    "\n",
    "    #print(cos_sims.values())\n",
    "    ax.boxplot(cos_sims.values(), labels=cos_sims.keys())\n",
    "\n",
    "    ax.xaxis.set_ticks_position('top')\n",
    "    ax.set_xticklabels(cos_sims.keys(), rotation=40, ha=\"left\")\n",
    "\n",
    "    # Cut the bars to be between 0.90 and 1\n",
    "    ax.set_ylim(0.6, 1.005)\n",
    "\n",
    "    if problems == sorted(per_problem_idx.keys()):\n",
    "        title_problems = \"all\"\n",
    "    else:\n",
    "        title_problems = \"\\n\".join(textwrap.wrap(str(problems), 50))\n",
    "    plt.title(f\"Cosine Similarity of User Embeddings\\nproblems={title_problems}\")\n",
    "    plt.show()\n",
    "\n",
    "plot_cos_similarities_vs_all(sorted(per_problem_idx.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a858af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "# Plot cosine similarity for all embeddings for some problems on one plot\n",
    "def plot_cos_sims_categories(categories=[\"first_success\", \"last_success\", \"first_failure\", \"last_failure\"]):\n",
    "    fig, ax = plt.subplots(figsize=(8,10))\n",
    "    cos_sims = {}\n",
    "    for category in categories:\n",
    "        cos_sims[category] = []\n",
    "        for problem_i, problem in enumerate(sorted(per_problem_idx.keys())):\n",
    "            gold_emb = gold_embs_by_name[problem]\n",
    "            user_embs = [all_embs[i][\"embedding\"] for i in per_problem_idx[problem] if all_embs[i][\"interaction\"][f\"is_{category}\"]]\n",
    "            appended_values = [calculate_cos_sim(gold_emb, user_emb) for user_emb in user_embs]\n",
    "            for emb_i, user_emb in enumerate(user_embs):\n",
    "                if appended_values[emb_i] < 0.75:\n",
    "                    golden_prompt = golden_prompts[problem]\n",
    "                    user_prompts = [all_embs[i][\"interaction\"][\"prompt\"] for i in per_problem_idx[problem] if all_embs[i][\"interaction\"][f\"is_{category}\"]]\n",
    "                    print(\"cos_sim < 0.75\")\n",
    "                    print(f\"problem: {problem}\")\n",
    "                    print(f\"category: {category}\")\n",
    "                    print(f\"golden_prompt:\\n{golden_prompt}\")\n",
    "                    print(f\"user_prompt:\\n{user_prompts[emb_i]}\")\n",
    "            cos_sims[category] += appended_values\n",
    "            \n",
    "\n",
    "    ax.boxplot(cos_sims.values(), labels=cos_sims.keys())\n",
    "    # Put labels at top\n",
    "    ax.xaxis.set_ticks_position('top')\n",
    "    ax.set_xticklabels(cos_sims.keys(), rotation=40, ha=\"left\")\n",
    "    \n",
    "    # Cut the bars to be between 0.90 and 1\n",
    "    ax.set_ylim(0.6, 1.005)\n",
    "\n",
    "    title_problems = \"\\n\".join(textwrap.wrap(str(categories), 50))\n",
    "    plt.title(f\"Cosine Similarity of User Embeddings to Canonical Embedding\\ncategories={title_problems}\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_cos_sims_categories()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
